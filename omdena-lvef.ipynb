{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import tensorflow as tf\n\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:34:57.049532Z","iopub.execute_input":"2023-04-04T13:34:57.050237Z","iopub.status.idle":"2023-04-04T13:34:57.091295Z","shell.execute_reply.started":"2023-04-04T13:34:57.050009Z","shell.execute_reply":"2023-04-04T13:34:57.090116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install scikit-video","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:34:57.094198Z","iopub.execute_input":"2023-04-04T13:34:57.094904Z","iopub.status.idle":"2023-04-04T13:35:12.188055Z","shell.execute_reply.started":"2023-04-04T13:34:57.094846Z","shell.execute_reply":"2023-04-04T13:35:12.186363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport imageio\nimport cv2\nimport os\nfrom tqdm import tqdm \nimport skvideo.io\nfrom glob import glob\n\ndf = pd.read_csv(\"/kaggle/input/heartdatabase/EchoNet-Dynamic/FileList.csv\")\nprint(f\"Total videos for training: {len(df)}\")\n\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:12.190401Z","iopub.execute_input":"2023-04-04T13:35:12.190969Z","iopub.status.idle":"2023-04-04T13:35:20.348727Z","shell.execute_reply.started":"2023-04-04T13:35:12.190913Z","shell.execute_reply":"2023-04-04T13:35:20.347400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/heartdatabase/EchoNet-Dynamic/Videos'\n\n# # Import metadata about the echo images\n# sequence_number = []\n# train_img_w = []\n# train_img_h = []\n# for i in tqdm(os.listdir(path)[0:100]):\n#     if i.endswith(\".avi\"):\n        \n#         number, width, height,_ = skvideo.io.vread(path +'/'+ i).shape\n#         sequence_number.append(number)\n#         train_img_w.append(width)\n#         train_img_h.append(height)\n        \n# for a,b,c in zip(sequence_number,train_img_w,train_img_h):\n#     print(a,b,c)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.351747Z","iopub.execute_input":"2023-04-04T13:35:20.352127Z","iopub.status.idle":"2023-04-04T13:35:20.358312Z","shell.execute_reply.started":"2023-04-04T13:35:20.352089Z","shell.execute_reply":"2023-04-04T13:35:20.356471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.hist(np.asarray(sequence_number), bins=10)\n# plt.title(\"Distribution of the number of image across all patients in the training set\")\n# plt.xlabel(\"Number of images in the echo loop\")\n# plt.ylabel(\"Number of patients\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.360139Z","iopub.execute_input":"2023-04-04T13:35:20.360558Z","iopub.status.idle":"2023-04-04T13:35:20.375899Z","shell.execute_reply.started":"2023-04-04T13:35:20.360525Z","shell.execute_reply":"2023-04-04T13:35:20.374653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min(df.NumberOfFrames)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.377582Z","iopub.execute_input":"2023-04-04T13:35:20.378023Z","iopub.status.idle":"2023-04-04T13:35:20.398610Z","shell.execute_reply.started":"2023-04-04T13:35:20.377985Z","shell.execute_reply":"2023-04-04T13:35:20.397319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = df[df[\"Split\"] == \"TRAIN\"]\ntrain_files = df.FileName[df[\"Split\"] == \"TRAIN\"]+'.avi'\n\ntrain_df = train_df.reset_index(drop=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.400090Z","iopub.execute_input":"2023-04-04T13:35:20.400546Z","iopub.status.idle":"2023-04-04T13:35:20.434580Z","shell.execute_reply.started":"2023-04-04T13:35:20.400489Z","shell.execute_reply":"2023-04-04T13:35:20.433742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_files = list(train_files)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.435798Z","iopub.execute_input":"2023-04-04T13:35:20.436319Z","iopub.status.idle":"2023-04-04T13:35:20.441982Z","shell.execute_reply.started":"2023-04-04T13:35:20.436286Z","shell.execute_reply":"2023-04-04T13:35:20.440794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = df[df[\"Split\"] == \"VAL\"]\nval_files = df.FileName[df[\"Split\"] == \"VAL\"]+'.avi'\nval_df = val_df.reset_index(drop=True)\nval_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.443783Z","iopub.execute_input":"2023-04-04T13:35:20.444622Z","iopub.status.idle":"2023-04-04T13:35:20.472967Z","shell.execute_reply.started":"2023-04-04T13:35:20.444582Z","shell.execute_reply":"2023-04-04T13:35:20.471559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#val_files = list(val_files)\nval_files","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.478565Z","iopub.execute_input":"2023-04-04T13:35:20.479522Z","iopub.status.idle":"2023-04-04T13:35:20.488824Z","shell.execute_reply.started":"2023-04-04T13:35:20.479420Z","shell.execute_reply":"2023-04-04T13:35:20.487277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = df[df[\"Split\"] == \"TEST\"]\ntest_files = df.FileName[df[\"Split\"] == \"TEST\"]+'.avi'\ntest_df = test_df.reset_index(drop=True)\ntest_df","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.490313Z","iopub.execute_input":"2023-04-04T13:35:20.491339Z","iopub.status.idle":"2023-04-04T13:35:20.517105Z","shell.execute_reply.started":"2023-04-04T13:35:20.491302Z","shell.execute_reply":"2023-04-04T13:35:20.515959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_files = list(test_files)\n#test_files","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.518314Z","iopub.execute_input":"2023-04-04T13:35:20.518666Z","iopub.status.idle":"2023-04-04T13:35:20.524110Z","shell.execute_reply.started":"2023-04-04T13:35:20.518635Z","shell.execute_reply":"2023-04-04T13:35:20.522867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train_df.EF[np.where(train_df.FileName == '0X234005774F4CB5CD')[0][0]]\ny","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.525539Z","iopub.execute_input":"2023-04-04T13:35:20.526168Z","iopub.status.idle":"2023-04-04T13:35:20.544576Z","shell.execute_reply.started":"2023-04-04T13:35:20.526132Z","shell.execute_reply":"2023-04-04T13:35:20.543575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Because of large filesize we may need to import the image data into Python in batches. \n# This can be done using batch generators.\n\ndef batch_generator(batch_size, gen_x):\n    batch_features = np.zeros((batch_size,28, 112, 112))\n    batch_labels = np.zeros((batch_size,1))\n    while True:\n        for i in range(batch_size):\n            batch_features[i] , batch_labels[i] = next(gen_x)\n        yield np.expand_dims(batch_features,4), batch_labels\n\ndef generate_data(filelist, img_path, gt_df):\n    while True:\n        for i in filelist:\n            if i.endswith(\".avi\"):\n                #print(i[:-4])\n                #img = np.load(img_path + i)\n                img = skvideo.io.vread(img_path +'/'+ i)[:, :, :, 0] \n                img = img[:28]\n                resized_img = np.zeros((28,112,112))\n                for j,k in enumerate(img):\n                    resized_img[j,:,:] = cv2.resize(k, (112,112), interpolation= cv2.INTER_LINEAR )/255\n                y = round(gt_df.EF[np.where(gt_df.FileName == i[:-4])[0][0]])\n\n                yield resized_img, y\n                ","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.546409Z","iopub.execute_input":"2023-04-04T13:35:20.547213Z","iopub.status.idle":"2023-04-04T13:35:20.564822Z","shell.execute_reply.started":"2023-04-04T13:35:20.547165Z","shell.execute_reply":"2023-04-04T13:35:20.563513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_data =batch_generator(16,generate_data(val_files,path,val_df))\nprint(\"The shape of one batch of valid images (batch size = 16):\")\nprint(next(val_data)[0].shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:20.566372Z","iopub.execute_input":"2023-04-04T13:35:20.566763Z","iopub.status.idle":"2023-04-04T13:35:24.762249Z","shell.execute_reply.started":"2023-04-04T13:35:20.566731Z","shell.execute_reply":"2023-04-04T13:35:24.760778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in next(val_data)[0][0]:\n    plt.imshow(i)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:24.764566Z","iopub.execute_input":"2023-04-04T13:35:24.765298Z","iopub.status.idle":"2023-04-04T13:35:34.312635Z","shell.execute_reply.started":"2023-04-04T13:35:24.765251Z","shell.execute_reply":"2023-04-04T13:35:34.311564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = batch_generator(5,generate_data(test_files,'/kaggle/input/heartdatabase/EchoNet-Dynamic/Videos',test_df))\n\nprint(\"The shape of one batch of test images (batch size = 5):\")\nprint(next(test)[0].shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:34.313853Z","iopub.execute_input":"2023-04-04T13:35:34.315102Z","iopub.status.idle":"2023-04-04T13:35:35.686106Z","shell.execute_reply.started":"2023-04-04T13:35:34.315061Z","shell.execute_reply":"2023-04-04T13:35:35.684396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in next(test)[0][0]:\n    plt.imshow(i)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:35.688507Z","iopub.execute_input":"2023-04-04T13:35:35.689528Z","iopub.status.idle":"2023-04-04T13:35:42.857344Z","shell.execute_reply.started":"2023-04-04T13:35:35.689445Z","shell.execute_reply":"2023-04-04T13:35:42.855985Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = tf.keras.models.Sequential()\n# model.add(\n#     tf.keras.layers.TimeDistributed(\n#         tf.keras.layers.Conv2D(32, (3,3), activation='relu'), \n#         input_shape=(28, 112, 112, 1) # 28 images...\n#     )\n# )\n# model.add(\n#     tf.keras.layers.TimeDistributed(\n#         tf.keras.layers.GlobalAveragePooling2D() # Or Flatten()\n#     )\n# )\n# model.add(\n#     tf.keras.layers.LSTM(32, activation='relu', return_sequences=False)\n# )\n# model.add(tf.keras.layers.Dense(1))\n# model.compile('adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:42.859048Z","iopub.execute_input":"2023-04-04T13:35:42.860440Z","iopub.status.idle":"2023-04-04T13:35:42.866995Z","shell.execute_reply.started":"2023-04-04T13:35:42.860388Z","shell.execute_reply":"2023-04-04T13:35:42.865391Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 16\n# num_epoch = 15\n# steps = len(train_files[0:500])//batch_size\n# print(steps)\n\n# history = model.fit(x= batch_generator(batch_size,generate_data(train_files[0:500],path,train_df)),\n#                     validation_data =(next(val_data)[0],next(val_data)[1]) ,\n#                     epochs=num_epoch, steps_per_epoch=steps,\n#                     verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:42.868838Z","iopub.execute_input":"2023-04-04T13:35:42.869252Z","iopub.status.idle":"2023-04-04T13:35:42.890343Z","shell.execute_reply.started":"2023-04-04T13:35:42.869217Z","shell.execute_reply":"2023-04-04T13:35:42.889106Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv3D, MaxPooling3D, Flatten, Dense\n\nmodel2 = Sequential()\n\n# Add a 3D convolutional layer to process the video input\nmodel2.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(28, 112, 112, 1)))\n\n# Add a 3D max pooling layer to reduce the spatial dimensions of the output\nmodel2.add(MaxPooling3D(pool_size=(2, 2, 2)))\n\n# Flatten the output from the previous layer to create a 1D feature vector\nmodel2.add(Flatten())\n\n# Add a fully connected layer with 64 units and ReLU activation\nmodel2.add(Dense(64, activation='relu'))\n\n# Add a final output layer with a single unit and linear activation to predict the ejection rate\nmodel2.add(Dense(1, activation='linear'))\n\n# Compile the model with the mean squared error loss and the Adam optimizer\nmodel2.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n\ncallbacks = tf.keras.callbacks.ModelCheckpoint(\n    'best.h5',\n    monitor = \"val_root_mean_squared_error\",\n    verbose= 1,\n    save_best_only= True)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:42.891946Z","iopub.execute_input":"2023-04-04T13:35:42.893107Z","iopub.status.idle":"2023-04-04T13:35:44.969245Z","shell.execute_reply.started":"2023-04-04T13:35:42.893061Z","shell.execute_reply":"2023-04-04T13:35:44.967875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nnum_epoch = 10\nsteps = len(train_files[0:500])//batch_size\nprint(steps)\n\nhistory = model2.fit(x= batch_generator(batch_size,generate_data(train_files[0:500],path,train_df)),\n                    validation_data =(next(val_data)[0],next(val_data)[1]) ,\n                    epochs=num_epoch, steps_per_epoch=steps,callbacks=callbacks,\n                    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T13:35:44.970922Z","iopub.execute_input":"2023-04-04T13:35:44.971321Z","iopub.status.idle":"2023-04-04T14:33:51.479895Z","shell.execute_reply.started":"2023-04-04T13:35:44.971286Z","shell.execute_reply":"2023-04-04T14:33:51.478103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm \n\npath = '/kaggle/input/heartdatabase/EchoNet-Dynamic/Videos'\nbest_model = tf.keras.models.load_model('best.h5')\ny_pred=[]\ny_true = []\nfor i in tqdm(sorted(os.listdir(path)[0:20])):\n    if i.endswith(\".avi\"):\n        #print(i[:-4])\n        #img = np.load(img_path + i)\n        img = skvideo.io.vread(path +'/'+ i)[:, :, :, 0] \n        img = img[:28]\n        resized_img = np.zeros((28,112,112))\n        for j,k in enumerate(img):\n            resized_img[j,:,:] = cv2.resize(k, (112,112), interpolation= cv2.INTER_LINEAR )/255\n        y_pred.append(best_model.predict(np.expand_dims(np.expand_dims(resized_img,3),0)))\n        y_true.append(df.EF[np.where(df.FileName == i[:-4])[0][0]])\n\n \nprint(y_pred)\nprint()\nprint(y_true)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-04T14:33:51.482226Z","iopub.execute_input":"2023-04-04T14:33:51.482670Z","iopub.status.idle":"2023-04-04T14:34:09.891223Z","shell.execute_reply.started":"2023-04-04T14:33:51.482630Z","shell.execute_reply":"2023-04-04T14:34:09.889836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.evaluate(test)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T14:34:09.893378Z","iopub.execute_input":"2023-04-04T14:34:09.893807Z","iopub.status.idle":"2023-04-04T14:34:09.899674Z","shell.execute_reply.started":"2023-04-04T14:34:09.893765Z","shell.execute_reply":"2023-04-04T14:34:09.898521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rate = '15'\ntmp_video = skvideo.io.vread('/kaggle/input/heartdatabase/EchoNet-Dynamic/Videos/0X3EAF0968B6971345.avi')\nprint(tmp_video.shape)\n\ntmp_video = skvideo.io.vread('/kaggle/input/heartdatabase/EchoNet-Dynamic/Videos/0X3EAF0968B6971345.avi', outputdict={'-r': rate})\nprint(tmp_video.shape)\n\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import animation\nfrom IPython.display import HTML\n\n# np array with shape (frames, height, width, channels)\nvideo = tmp_video\n\nfig = plt.figure()\nim = plt.imshow(video[0,:,:,:])\n\nplt.close() # this is required to not display the generated image\n\ndef init():\n    im.set_data(video[0,:,:,:])\ndef animate(i):\n    im.set_data(video[i,:,:,:])\n    return im\n\nanim = animation.FuncAnimation(fig, animate, init_func=init, frames=video.shape[0],interval=video.shape[0])\nHTML(anim.to_html5_video())","metadata":{"execution":{"iopub.status.busy":"2023-04-04T14:34:09.901367Z","iopub.execute_input":"2023-04-04T14:34:09.901784Z","iopub.status.idle":"2023-04-04T14:34:14.505064Z","shell.execute_reply.started":"2023-04-04T14:34:09.901750Z","shell.execute_reply":"2023-04-04T14:34:14.503573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}